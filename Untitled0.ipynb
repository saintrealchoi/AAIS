{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "McCS1S8puqoT",
        "outputId": "9a74c64d-773a-4f37-92c9-b00a12939441"
      },
      "source": [
        "# !pip uninstall tensorflow\n",
        "# !pip install tensorflow-gpu==1.13.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.4.1:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-2.4.1.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.4.1\n",
            "Collecting tensorflow-gpu==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/65/8dc8fc4a263a24f7ad935b72ad35e72ba381cb9e175b6a5fe086c85f17a7/tensorflow_gpu-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (345.0MB)\n",
            "\u001b[K     |████████████████████████████████| 345.0MB 51kB/s \n",
            "\u001b[?25hCollecting keras-applications>=1.0.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.32.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.12.0)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (3.12.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.36.2)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.13.1) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.13.1) (2.10.0)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/03/b7e605db4a57c0f6fba744b11ef3ddf4ddebcada35022927a2b5fc623fdf/mock-4.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.13.1) (56.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow-gpu==1.13.1) (3.4.1)\n",
            "Installing collected packages: keras-applications, mock, tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "Successfully installed keras-applications-1.0.8 mock-4.0.3 tensorboard-1.13.1 tensorflow-estimator-1.13.0 tensorflow-gpu-1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6hop9m_P1nn",
        "outputId": "a10ebac3-f09a-44b1-8f3c-07c3c5b12d8f"
      },
      "source": [
        "# !pip install keras"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX9wFp0vvE0i",
        "outputId": "aba972a9-7b4c-4e8f-fb9f-0243d7d31c94"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_iKQoMSQF9F"
      },
      "source": [
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDxsfIZ4QLzf"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 30,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr7oULy6s3vI"
      },
      "source": [
        "# ADAM optimizer\n",
        "LR = 0.001\n",
        "BETA1= 0.9\n",
        "BETA2= 0.999\n",
        "EPSILON = 1e-08\n",
        "\n",
        "# Batch Normalization\n",
        "batch_prob = tf.placeholder(tf.bool)\n",
        "BATCH_PROB = True\n",
        "\n",
        "# Dropout\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "KEEP_PROB = 0.75\n",
        "\n",
        "training_epochs = 75\n",
        "batch_size = 128\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLEfBSC2uIzu"
      },
      "source": [
        "def batch_data(shuffled_idx, batch_size, data, labels, start_idx):\n",
        "    idx = shuffled_idx[start_idx:start_idx+batch_size]\n",
        "    data_shuffle = [data[i] for i in idx]\n",
        "    labels_shuffle = [labels[i] for i in idx]\n",
        "\n",
        "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De15TOpfuJot"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "def build_CNN_classifier(x):\n",
        "    x_image = x\n",
        "\n",
        "    W1 = tf.get_variable(name=\"W1\", shape=[3, 3, 3, 64], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    b1 = tf.get_variable(name=\"b1\", shape=[64], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    c1 = tf.nn.conv2d(x_image, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    l1 = tf.nn.relu(tf.nn.bias_add(c1, b1))\n",
        "    n1 = tf.layers.batch_normalization(l1)#,center=True,scale=True,training=batch_prob)\n",
        "    l1_pool = tf.nn.max_pool(n1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    # l1_pool_drop = tf.nn.dropout(l1_pool,keep_prob=KEEP_PROB)\n",
        "\n",
        "    W2 = tf.get_variable(name=\"W2\", shape=[3, 3, 64, 48], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    b2 = tf.get_variable(name=\"b2\", shape=[48], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    c2 = tf.nn.conv2d(l1_pool, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    l2 = tf.nn.relu(tf.nn.bias_add(c2, b2))\n",
        "    l2_drop = tf.nn.dropout(l2,keep_prob=KEEP_PROB)\n",
        "    n2 = tf.layers.batch_normalization(l2_drop)\n",
        "    l2_pool = tf.nn.max_pool(n2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "    \n",
        "    W3 = tf.get_variable(name=\"W3\", shape=[3, 3, 48, 32], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    b3 = tf.get_variable(name=\"b3\", shape=[32], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    c3 = tf.nn.conv2d(l2_pool, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
        "    l3 = tf.nn.relu(tf.nn.bias_add(c3, b3))\n",
        "    n3 = tf.layers.batch_normalization(l3)\n",
        "    l3_pool = tf.nn.max_pool(n3, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
        "    \n",
        "    l3_flat = tf.reshape(l3_pool, [-1, 8*8*32])\n",
        "\n",
        "    W_fc = tf.get_variable(name=\"W_fc\", shape=[8*8*32, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    b_fc = tf.get_variable(name=\"b_fc\", shape=[10], initializer=tf.contrib.layers.xavier_initializer())\n",
        "    logits = tf.nn.bias_add(tf.matmul(l3_flat, W_fc), b_fc)\n",
        "    hypothesis = tf.nn.softmax(logits)\n",
        "\n",
        "    return hypothesis, logits"
      ],
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAnx1687uKJu"
      },
      "source": [
        "ckpt_path = \"/content/drive/MyDrive/Colab Notebooks/assignment/image classification/output\""
      ],
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi2bkonXuNKG",
        "outputId": "6ce36348-23de-4d55-cac8-46bb8af94adc"
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "\n",
        "x_train = np.load(\"/content/drive/MyDrive/Colab Notebooks/assignment/image classification/data/x_train.npy\")\n",
        "y_train = np.load(\"/content/drive/MyDrive/Colab Notebooks/assignment/image classification/data/y_train.npy\")\n",
        "\n",
        "print(np.shape(x_train))\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "print(np.shape(x_train))\n",
        "\n",
        "dev_num = len(x_train) // 4\n",
        "\n",
        "x_dev = x_train[:dev_num]\n",
        "y_dev = y_train[:dev_num]\n",
        "\n",
        "x_train = x_train[dev_num:]\n",
        "y_train = y_train[dev_num:]\n",
        "\n",
        "y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
        "y_dev_one_hot = tf.squeeze(tf.one_hot(y_dev, 10),axis=1)\n",
        "\n",
        "y_pred, logits = build_CNN_classifier(x)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
        "train_step = tf.train.AdamOptimizer(\n",
        "    learning_rate=LR,\n",
        "    beta1=BETA1,\n",
        "    beta2=BETA2,\n",
        "    epsilon=EPSILON,\n",
        "    use_locking=False,\n",
        "    name='Adam').minimize(cost)\n",
        "\n",
        "total_batch = int(len(x_train)/batch_size) if len(x_train)%batch_size == 0 else int(len(x_train)/batch_size) + 1\n"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 32, 32, 3)\n",
            "(48000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kUTeT6785fu"
      },
      "source": [
        "with tf.name_scope('accruacy'):\n",
        "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    tf.summary.scalar('accruacy', accuracy)"
      ],
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQjoKA5tuTyF",
        "outputId": "cbe38482-055e-4c61-fbfb-eda44f99bb8b"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    print(\"학습시작\")\n",
        "\n",
        "    for epoch in range(training_epochs):\n",
        "        # print(\"Epoch\", epoch+1)\n",
        "        start = 0\n",
        "        avg_cost = 0\n",
        "        shuffled_idx = np.arange(0, len(x_train))\n",
        "        np.random.shuffle(shuffled_idx)\n",
        "        \n",
        "\n",
        "        for i in range(total_batch):\n",
        "            batch = batch_data(shuffled_idx, batch_size, x_train, y_train_one_hot.eval(), i*batch_size)\n",
        "            c, _ = sess.run([cost,train_step], feed_dict={x: batch[0], y: batch[1]})\n",
        "            avg_cost+= c / total_batch\n",
        "            \n",
        "        [train_accruacy] = sess.run([accuracy], feed_dict={x:batch[0], y:batch[1]}) # works\n",
        "        # [s, train_accruacy] = sess.run([summ, accuracy], feed_dict={x:batch[0], y:batch[1]}) #error!\n",
        "        print(\"Epoch : %d, training accruacy : %g, cost : %g\" % (epoch+1, train_accruacy, avg_cost))\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            y_prediction = np.argmax(y_pred.eval(feed_dict={x: x_dev}), 1)\n",
        "            y_true = np.argmax(y_dev_one_hot.eval(), 1)\n",
        "            dev_f1 = f1_score(y_true, y_prediction, average=\"weighted\") # f1 스코어 측정\n",
        "            print(\" dev 데이터 f1 score: %f\" % dev_f1)\n",
        "    \n",
        "    saver = tf.train.Saver()\n",
        "    saver.save(sess, ckpt_path)\n",
        "    saver.restore(sess, ckpt_path)\n",
        "\n",
        "    y_prediction = np.argmax(y_pred.eval(feed_dict={x: x_dev}), 1)\n",
        "    y_true = np.argmax(y_dev_one_hot.eval(), 1)\n",
        "    dev_f1 = f1_score(y_true, y_prediction, average=\"weighted\") # f1 스코어 측정\n",
        "    print(\"dev 데이터 f1 score: %f\" % dev_f1)\n",
        "\n",
        "    # 밑에는 건드리지 마세요\n",
        "    x_test = np.load(\"/content/drive/MyDrive/Colab Notebooks/assignment/image classification/data/x_test.npy\")\n",
        "    test_logits = y_pred.eval(feed_dict={x: x_test})\n",
        "    np.save(\"result\", test_logits)"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "학습시작\n",
            "Epoch : 1, training accruacy : 0.3125, cost : 3.32327\n",
            " dev 데이터 f1 score: 0.351650\n",
            "Epoch : 2, training accruacy : 0.46875, cost : 1.66576\n",
            "Epoch : 3, training accruacy : 0.46875, cost : 1.49621\n",
            "Epoch : 4, training accruacy : 0.59375, cost : 1.38576\n",
            "Epoch : 5, training accruacy : 0.71875, cost : 1.2938\n",
            "Epoch : 6, training accruacy : 0.625, cost : 1.22311\n",
            "Epoch : 7, training accruacy : 0.6875, cost : 1.17551\n",
            "Epoch : 8, training accruacy : 0.75, cost : 1.12189\n",
            "Epoch : 9, training accruacy : 0.6875, cost : 1.07552\n",
            "Epoch : 10, training accruacy : 0.71875, cost : 1.04118\n",
            "Epoch : 11, training accruacy : 0.65625, cost : 1.01091\n",
            " dev 데이터 f1 score: 0.625913\n",
            "Epoch : 12, training accruacy : 0.78125, cost : 0.981943\n",
            "Epoch : 13, training accruacy : 0.625, cost : 0.956231\n",
            "Epoch : 14, training accruacy : 0.8125, cost : 0.923127\n",
            "Epoch : 15, training accruacy : 0.71875, cost : 0.904969\n",
            "Epoch : 16, training accruacy : 0.65625, cost : 0.883678\n",
            "Epoch : 17, training accruacy : 0.84375, cost : 0.86236\n",
            "Epoch : 18, training accruacy : 0.53125, cost : 0.838435\n",
            "Epoch : 19, training accruacy : 0.8125, cost : 0.81709\n",
            "Epoch : 20, training accruacy : 0.75, cost : 0.804997\n",
            "Epoch : 21, training accruacy : 0.65625, cost : 0.788938\n",
            " dev 데이터 f1 score: 0.673898\n",
            "Epoch : 22, training accruacy : 0.875, cost : 0.770253\n",
            "Epoch : 23, training accruacy : 0.625, cost : 0.750892\n",
            "Epoch : 24, training accruacy : 0.71875, cost : 0.742428\n",
            "Epoch : 25, training accruacy : 0.84375, cost : 0.723821\n",
            "Epoch : 26, training accruacy : 0.65625, cost : 0.711897\n",
            "Epoch : 27, training accruacy : 0.8125, cost : 0.690906\n",
            "Epoch : 28, training accruacy : 0.8125, cost : 0.682134\n",
            "Epoch : 29, training accruacy : 0.84375, cost : 0.671713\n",
            "Epoch : 30, training accruacy : 0.84375, cost : 0.65616\n",
            "Epoch : 31, training accruacy : 0.84375, cost : 0.644108\n",
            " dev 데이터 f1 score: 0.686435\n",
            "Epoch : 32, training accruacy : 0.875, cost : 0.626947\n",
            "Epoch : 33, training accruacy : 0.75, cost : 0.614875\n",
            "Epoch : 34, training accruacy : 0.90625, cost : 0.604079\n",
            "Epoch : 35, training accruacy : 0.8125, cost : 0.596023\n",
            "Epoch : 36, training accruacy : 0.8125, cost : 0.578695\n",
            "Epoch : 37, training accruacy : 0.71875, cost : 0.582864\n",
            "Epoch : 38, training accruacy : 0.9375, cost : 0.566058\n",
            "Epoch : 39, training accruacy : 0.8125, cost : 0.568411\n",
            "Epoch : 40, training accruacy : 0.875, cost : 0.552805\n",
            "Epoch : 41, training accruacy : 0.875, cost : 0.540311\n",
            " dev 데이터 f1 score: 0.677428\n",
            "Epoch : 42, training accruacy : 0.875, cost : 0.527035\n",
            "Epoch : 43, training accruacy : 0.9375, cost : 0.524596\n",
            "Epoch : 44, training accruacy : 0.8125, cost : 0.52093\n",
            "Epoch : 45, training accruacy : 0.90625, cost : 0.516812\n",
            "Epoch : 46, training accruacy : 0.90625, cost : 0.501352\n",
            "Epoch : 47, training accruacy : 0.84375, cost : 0.496921\n",
            "Epoch : 48, training accruacy : 0.75, cost : 0.503702\n",
            "Epoch : 49, training accruacy : 0.875, cost : 0.479966\n",
            "Epoch : 50, training accruacy : 0.875, cost : 0.477889\n",
            "Epoch : 51, training accruacy : 0.90625, cost : 0.473149\n",
            " dev 데이터 f1 score: 0.691226\n",
            "Epoch : 52, training accruacy : 0.84375, cost : 0.474877\n",
            "Epoch : 53, training accruacy : 0.90625, cost : 0.462403\n",
            "Epoch : 54, training accruacy : 0.84375, cost : 0.452581\n",
            "Epoch : 55, training accruacy : 0.875, cost : 0.452128\n",
            "Epoch : 56, training accruacy : 0.96875, cost : 0.446318\n",
            "Epoch : 57, training accruacy : 0.875, cost : 0.447716\n",
            "Epoch : 58, training accruacy : 0.875, cost : 0.443151\n",
            "Epoch : 59, training accruacy : 0.84375, cost : 0.436459\n",
            "Epoch : 60, training accruacy : 0.8125, cost : 0.422814\n",
            "Epoch : 61, training accruacy : 1, cost : 0.418925\n",
            " dev 데이터 f1 score: 0.700982\n",
            "Epoch : 62, training accruacy : 0.84375, cost : 0.412509\n",
            "Epoch : 63, training accruacy : 0.875, cost : 0.412108\n",
            "Epoch : 64, training accruacy : 0.78125, cost : 0.419839\n",
            "Epoch : 65, training accruacy : 0.90625, cost : 0.402741\n",
            "Epoch : 66, training accruacy : 0.9375, cost : 0.399236\n",
            "Epoch : 67, training accruacy : 1, cost : 0.396221\n",
            "Epoch : 68, training accruacy : 0.78125, cost : 0.38363\n",
            "Epoch : 69, training accruacy : 0.875, cost : 0.393814\n",
            "Epoch : 70, training accruacy : 0.96875, cost : 0.380786\n",
            "Epoch : 71, training accruacy : 0.9375, cost : 0.376439\n",
            " dev 데이터 f1 score: 0.692965\n",
            "Epoch : 72, training accruacy : 0.90625, cost : 0.375967\n",
            "Epoch : 73, training accruacy : 0.875, cost : 0.378311\n",
            "Epoch : 74, training accruacy : 0.875, cost : 0.369609\n",
            "Epoch : 75, training accruacy : 0.9375, cost : 0.361957\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/MyDrive/Colab Notebooks/assignment/image classification/output\n",
            "dev 데이터 f1 score: 0.690917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVuNqhdCuNUE"
      },
      "source": [
        ""
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4QCPuKfuNjT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}